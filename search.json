[
  {
    "objectID": "index.html#è¼ªèª­ä¼šã«ã‚ãŸã£ã¦",
    "href": "index.html#è¼ªèª­ä¼šã«ã‚ãŸã£ã¦",
    "title": "å¼·åŒ–å­¦ç¿’ è¼ªèª­ä¼š",
    "section": "è¼ªèª­ä¼šã«ã‚ãŸã£ã¦",
    "text": "è¼ªèª­ä¼šã«ã‚ãŸã£ã¦\nç¬¬ï¼‘ç« ä»¥é™ã€ã¨ãã«ç¬¬â…¡éƒ¨ï¼ˆç¬¬ï¼™ç« ã€œï¼‰ã‹ã‚‰ã¯ãã‚Œãã‚ŒãŒç‹¬ç«‹ã—ãŸå†…å®¹ãŒå¤šã„ã€‚\næœ€åˆã«ã™ã¹ã¦ã®é›£æ˜“åº¦ã‚’æŠŠæ¡ã™ã‚‹ã®ã¯é›£ã—ã„ã®ã§ã€æ¯é€±æ¬¡å›ã®æ‹…å½“ç¯„å›²ã‚’æ±ºã‚ã‚‹ã“ã¨ã¨ã™ã‚‹ã€‚\næœ¬ã®å†…å®¹ã«æ²¿ã£ã¦è§£èª¬ã—ã¦ã„ãã€ã‚ã‹ã‚‰ãªã„ã¨ã“ã‚ãŒã‚ã‚Œã°èãæ‰‹ã¯ã‚ˆã“ã‚„ã‚Šã‚’å…¥ã‚Œã¦è³ªå•ã‚’ã—ã¦ã‚ˆã„ã€‚\næ‹…å½“è€…ã¯ã™ã¹ã¦ã®è³ªå•ã«ç­”ãˆã‚‰ã‚Œã‚‹ã‚ˆã†ã«æº–å‚™ã™ã‚‹ã€‚"
  },
  {
    "objectID": "index.html#å½“æ›¸ã§ä½¿ã‚ã‚Œã‚‹è¨˜å·",
    "href": "index.html#å½“æ›¸ã§ä½¿ã‚ã‚Œã‚‹è¨˜å·",
    "title": "å¼·åŒ–å­¦ç¿’ è¼ªèª­ä¼š",
    "section": "å½“æ›¸ã§ä½¿ã‚ã‚Œã‚‹è¨˜å·",
    "text": "å½“æ›¸ã§ä½¿ã‚ã‚Œã‚‹è¨˜å·\n\n```{python}\n1 + 1\n```\n\n2"
  },
  {
    "objectID": "index.html#ä»Šå¾Œã®é€²ã‚æ–¹",
    "href": "index.html#ä»Šå¾Œã®é€²ã‚æ–¹",
    "title": "å¼·åŒ–å­¦ç¿’ è¼ªèª­ä¼š",
    "section": "ä»Šå¾Œã®é€²ã‚æ–¹",
    "text": "ä»Šå¾Œã®é€²ã‚æ–¹\näºŒäººã§å…±é€šã®æ–‡æ›¸ã‚’ç·¨é›†ã™ã‚‹å½¢å¼ã«è³›æˆã§ã‚ã‚Œã°ã€æ¬¡å›ã¾ã§ã«ã“ã®æ–‡æ›¸ã‚’ã‚µãƒ¼ãƒãƒ¼ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€å³»å¹³ã¸ã®å°å…¥æ–¹æ³•ã‚’è€ƒãˆã¦ãŠãã€‚\n\n\n\næ—¥æ™‚\nã‚ã\nå³»å¹³\n\n\n\n\n11/30\nåºç« \n\n\n\n12/5\nç¬¬ä¸€ç« \n\n\n\n12/12\nç¬¬äºŒç« å‰åŠï¼Ÿ\nç¬¬äºŒç« å¾ŒåŠï¼Ÿ\n\n\n12/19\n\n\n\n\n12/26\n\n\n\n\n1/2\n\n\n\n\n\nãã†ã§ãªã‘ã‚Œã°ã€ä¾‹ãˆã°ä¸€äººã¯bookå½¢å¼ã€ã‚‚ã†ä¸€äººã¯ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”¨ã„ã¦ç™ºè¡¨ã™ã‚‹ã€‚"
  },
  {
    "objectID": "index.html#æ–‡æ›¸ã®ç·¨é›†æ–¹æ³•",
    "href": "index.html#æ–‡æ›¸ã®ç·¨é›†æ–¹æ³•",
    "title": "å¼·åŒ–å­¦ç¿’ è¼ªèª­ä¼š",
    "section": "æ–‡æ›¸ã®ç·¨é›†æ–¹æ³•",
    "text": "æ–‡æ›¸ã®ç·¨é›†æ–¹æ³•\n\ngitç’°å¢ƒã‚’æ•´ãˆã‚‹ã€‚ï¼ˆwslãŒãŠã™ã™ã‚ï¼‰\nrstudioã¨quartoã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\nhttps://github.com/Roku-3/rindoku_RLã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã€mainãƒ–ãƒ©ãƒ³ãƒã§ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã™ã‚‹ã€‚rstudioã§é–‹ãã€‚\n\n\nç·¨é›†å†…å®¹ã‚’é©å¿œã™ã‚‹\ngitã®åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰ã¯ä»¥ä¸‹ã®é€šã‚Šã€‚\ngit pull origin HEAD            # githubã‹ã‚‰ãƒ­ãƒ¼ã‚«ãƒ«ã«å·®åˆ†ã‚’ã‚‚ã£ã¦ãã‚‹\n\ngit add .                       # å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒŸãƒƒãƒˆå¯¾è±¡ã«ã™ã‚‹\n\ngit commit -m \"edit chapter 2\"  # ç·¨é›†å†…å®¹ã‚’è¡¨ã™ã‚³ãƒ¡ãƒ³ãƒˆä»˜ãã§ã‚³ãƒŸãƒƒãƒˆã™ã‚‹ã€‚\n                                # -mã¯ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¸€è¡Œã«ã™ã‚‹ã¨ã„ã†æ„å‘³\n                                \ngit push origin HEAD            # githubã«æƒ…å ±ã‚’é€ã‚‹\n2äººãŒåŒã˜å ´æ‰€ã‚’å¤‰æ›´ã—ã¦ã„ãŸå ´åˆã€ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆãŒç™ºç”Ÿã™ã‚‹ã€‚ãã®æ™‚ã¯å¿…ãšè§£æ¶ˆã—ã¦ã‹ã‚‰pushã‚’è¡Œã†ã€‚\ngit branchã¨å…¥åŠ›ã—ãŸã¨ãã«mainã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰pushã™ã‚‹ã“ã¨ã€‚\npushãŒæ­£å¸¸ã«è¡Œã‚ã‚Œã‚‹ã¨è‡ªå‹•ã§ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆã‚µã‚¤ãƒˆãŒå…¬é–‹ï¼‰ã•ã‚Œã‚‹ã€‚\n\n\nä»Šå¾Œã®é‹ç”¨\nä¸€äººãŒæ–‡æ›¸ã‚’å¤‰æ›´ã—ã¦é©å¿œã—ãŸå¾Œã€ç´°ã‹ã„ãƒŸã‚¹ãªã©ã§å†ç·¨é›†ã™ã‚‹ã®ã¯æ‰‹é–“ã€‚ã¾ãŸé–“é•ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦ã—ã¾ã£ãŸæ™‚ã®å±é™ºæ€§ã‚‚é«˜ã„ã€‚\nãã®ãŸã‚ã€å¾Œã€…ã¯ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡ºã—ã¦ã‚‚ã†ä¸€äººãŒç¢ºèªã™ã‚‹å½¢å¼ã«ã—ã‚ˆã†ã¨æ€ã†ã€‚\nãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯æ‰‹è»½ã«äººã®ç·¨é›†ã‚’ç¢ºèªãƒ»è¨‚æ­£ã§ãã‚‹githubã®æ©Ÿèƒ½ã§ã‚ã‚‹ã€‚"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "åºç« ã®ã¾ã¨ã‚",
    "section": "",
    "text": "ç¬¬ï¼‘ç‰ˆåºæ–‡\nå¼·åŒ–å­¦ç¿’ã¯197Xå¹´ã”ã‚ã‹ã‚‰å­˜åœ¨ãŒçŸ¥ã‚‰ã‚Œã¦ããŸã€‚\nã—ã‹ã—ã€ç­†è€…ã¯ç’°å¢ƒã‹ã‚‰ã©ã®ã‚ˆã†ã«ã—ã¦å­¦ç¿’ã™ã‚‹ã‹ã€ã¨ã„ã†ã“ã¨ã«ã•ã»ã©æ³¨ç›®ã•ã‚Œã¦ã„ãªã„ã“ã¨ã«æ°—ãŒã¤ã„ãŸã€‚"
  },
  {
    "objectID": "chapter1.html#å…·ä½“çš„ãªæ§‹æˆè¦ç´ ",
    "href": "chapter1.html#å…·ä½“çš„ãªæ§‹æˆè¦ç´ ",
    "title": "ç¬¬ï¼‘ç« :å¼·åŒ–å­¦ç¿’ã¨ã¯",
    "section": "å…·ä½“çš„ãªæ§‹æˆè¦ç´ ",
    "text": "å…·ä½“çš„ãªæ§‹æˆè¦ç´ \n\n\n\n\n\n\n\næ–¹ç­–(policy)\nã‚ã‚‹çŠ¶æ…‹ã§ã®ãã“ã‹ã‚‰ã¨ã‚‹ã¹ãè¡Œå‹•ã¸ã®å†™åƒ\n\n\nå ±é…¬(reward)\nå„æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®è¡Œå‹•ã‚’è©•ä¾¡ã—ã¦ç’°å¢ƒã‹ã‚‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«é€ã‚‰ã‚Œã‚‹ã‚‚ã®ã€‚\n\n\nä¾¡å€¤é–¢æ•°(value function)\nå ±é…¬ã¨ã¯é•ã„ã€ãã®çŠ¶æ…‹ã®é•·æœŸçš„ãªä¾¡å€¤ã‚’å°ãã€‚\n\n\nãƒ¢ãƒ‡ãƒ«(model)\nç’°å¢ƒã®æŒ™å‹•ã‚’æ¨¡å€£ã™ã‚‹ã€ä¸»ã«æœªæ¥ã®ç’°å¢ƒï¼ˆçŠ¶æ…‹é·ç§»ã¨å ±é…¬ï¼‰ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã®é–¢æ•°ç¾¤ã€‚\n\n\n\nå¼·åŒ–å­¦ç¿’ã®æœ€çµ‚ç›®æ¨™ã¯ã“ã®å ±é…¬ã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚\nï¼”ã¤ç›®ã®ç’°å¢ƒãƒ¢ãƒ‡ãƒ«ã¯å¿…é ˆè¦ç´ ã§ã¯ãªãã€ä½¿ç”¨ã—ãŸã‚‚ã®ã‚’ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã€ã—ã¦ã„ãªã„ã‚‚ã®ã‚’ãƒ¢ãƒ‡ãƒ«ãƒ•ãƒªãƒ¼æ‰‹æ³•ã¨å‘¼ã¶ã€‚"
  },
  {
    "objectID": "chapter1.html#é€²åŒ–çš„æ‰‹æ³•ã¨ã®é•ã„",
    "href": "chapter1.html#é€²åŒ–çš„æ‰‹æ³•ã¨ã®é•ã„",
    "title": "ç¬¬ï¼‘ç« :å¼·åŒ–å­¦ç¿’ã¨ã¯",
    "section": "é€²åŒ–çš„æ‰‹æ³•ã¨ã®é•ã„",
    "text": "é€²åŒ–çš„æ‰‹æ³•ã¨ã®é•ã„\nï¼ˆå½“æ›¸ã§ã¯åˆ¥ã®ã‚‚ã®ã¨ã—ã¦æ‰ãˆã¦ã„ã‚‹ãŒã€é€²åŒ–çš„æ‰‹æ³•ã‚’å¼·åŒ–å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ä¸€æ´¾ã¨ã™ã‚‹è€ƒãˆæ–¹ã‚‚ã‚ã‚‹ã€‚ï¼‰\néºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€éºä¼çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã€ç„¼ããªã¾ã—æ³•ãªã©ã‚’é€²åŒ–çš„æ‰‹æ³•ã¨å‘¼ã¶ã€‚ã“ã‚Œã‚‰ã¯ç”Ÿç‰©ã®ã‚ˆã†ã«å„ªã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç‰¹å¾´ã‚’å¼•ãç¶™ã„ã§æ¬¡ã®ä¸–ä»£ãŒç²å¾—ã™ã‚‹å ±é…¬ã‚’å¤§ããã™ã‚‹ã€‚\nç’°å¢ƒã‹ã‚‰ã®æƒ…å ±ã‚’ã‚‚ã¨ã«è¡Œå‹•ã—ã€å ±é…¬ã‚’æœ€å¤§åŒ–ã™ã‚‹ã¨ã„ã†ç‚¹ã§å¼·åŒ–å­¦ç¿’ã¨ä¼¼ã¦ã„ã‚‹ãŒã€æœ€åˆã«è¿°ã¹ãŸç’°å¢ƒã¨ã®ç›¸äº’ä½œç”¨ãŒãªã„ã¨ã„ã†ç‚¹ã§ç•°ãªã‚‹ã€‚\nã¤ã¾ã‚Šã€é€²åŒ–çš„æ‰‹æ³•ã§ã¯ã©ã®çŠ¶æ…‹ã§ã©ã®è¡Œå‹•ã‚’å–ã£ãŸã®ã‹ã€ã¨ã„ã†æƒ…å ±ã‚’ä½¿ã‚ãªã„ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç’°å¢ƒã®çŠ¶æ…‹ã‚’çŸ¥è¦šã—ã¥ã‚‰ã„ï¼ˆæ•°å€¤åŒ–ãŒé›£ã—ã„ï¼‰å ´åˆãªã©ã‚’é™¤ã„ã¦ã€å¼·åŒ–å­¦ç¿’ã®ã»ã†ãŒåŠ¹ç‡çš„ã«å­¦ç¿’ã§ãã‚‹ã“ã¨ãŒå¤šã„ã€‚"
  },
  {
    "objectID": "chapter1.html#ã‚·ãƒ³ãƒ—ãƒ«ãªä¾‹ä¸‰ç›®ä¸¦ã¹",
    "href": "chapter1.html#ã‚·ãƒ³ãƒ—ãƒ«ãªä¾‹ä¸‰ç›®ä¸¦ã¹",
    "title": "ç¬¬ï¼‘ç« :å¼·åŒ–å­¦ç¿’ã¨ã¯",
    "section": "ã‚·ãƒ³ãƒ—ãƒ«ãªä¾‹ï¼šä¸‰ç›®ä¸¦ã¹",
    "text": "ã‚·ãƒ³ãƒ—ãƒ«ãªä¾‹ï¼šä¸‰ç›®ä¸¦ã¹\nå¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦ä¸‰ç›®ä¸¦ã¹ã«å‹ã¤ã“ã¨ã‚’ç›®æ¨™ã¨ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œã‚‹ã€‚\nä»¥ä¸‹ã®ã‚ˆã†ãªè¡Œå‹•æœ¨ã‚’ä½œæˆã™ã‚‹ã€‚ãã‚Œãã‚Œã®çŠ¶æ…‹ï¼ˆç›¤é¢ï¼‰ã«ã¯0~1ã®ä¾¡å€¤ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã€‚ã©ã†ã‚„ã£ã¦ã‚‚è² ã‘ã‚‹çŠ¶æ…‹ã«ã¯0ã€æ—¢ã«å‹ã£ã¦ã„ã‚‹çŠ¶æ…‹ã«ã¯1ã€ãã‚Œä»¥å¤–ã«ã¯0.5ãŒåˆæœŸå€¤ã¨ã—ã¦å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹ã€‚\nå­¦ç¿’ä¸­ã€åŸºæœ¬çš„ã«ã¯ä¾¡å€¤ãŒå¤§ãã„ã€å‹ç‡ãŒé«˜ã„æ‰‹ã‚’é¸ã¶ãŒã€ã™ã¹ã¦ã®çŠ¶æ…‹ã‚’è©¦ã™ãŸã‚ã«ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’æŒã£ãŸè¡Œå‹•é¸æŠï¼ˆæ¢ç´¢çš„ãªæ‰‹ï¼‰ã‚’ã•ã›ã‚‹ã€‚\nçŠ¶æ…‹ã®ä¾¡å€¤ã®æ›´æ–°ã¯ä»¥ä¸‹ã®å¼ã§è¡Œã†ã€‚\n\\[\nV(s_t) \\leftarrow V(s_t)+\\alpha\\left[V\\left(s_{t+1}\\right)-V(s_t)\\right]\n\\]\n\\(V(s)\\)ã¯çŠ¶æ…‹\\(s\\)ã®æ¨å®šä¾¡å€¤ã‚’è¡¨ã—ã€æ¬¡ã®æ‰‹ã‚’é¸æŠã—ãŸéš›ã€æ¬¡ã®çŠ¶æ…‹ã®ä¾¡å€¤ã«è¿‘ã¥ã‘ã¦ã„ã‚‹ã€‚ã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\\(\\alpha\\)ã«ã‚ˆã£ã¦å­¦ç¿’ç‡ã‚’èª¿æ•´ã—ã¦ã„ã‚‹ã€‚\nã“ã®æ›´æ–°å‰‡ã¯TDå­¦ç¿’ï¼ˆæ™‚é–“å·®åˆ†å­¦ç¿’; temporal-difference learningï¼‰ã¨å‘¼ã°ã‚Œã‚‹ã€‚"
  },
  {
    "objectID": "chapter1.html#ç·´ç¿’å•é¡Œ",
    "href": "chapter1.html#ç·´ç¿’å•é¡Œ",
    "title": "ç¬¬ï¼‘ç« :å¼·åŒ–å­¦ç¿’ã¨ã¯",
    "section": "ç·´ç¿’å•é¡Œ",
    "text": "ç·´ç¿’å•é¡Œ\n1.1 è‡ªå·±å¯¾æˆ¦ï¼ˆself playï¼‰\n\n```{python}\n    '''\n    import numpy as np\n    import pickle\n    '''\n```\n\n'\\nimport numpy as np\\nimport pickle\\n'\n\n\n\n```{python}\n    \"\"\"\n\n    BOARD_ROWS = 3\n    BOARD_COLS = 3\n    BOARD_SIZE = BOARD_ROWS * BOARD_COLS\n\n    class State:\n        def __init__(self):\n            self.data = np.zeros((BOARD_ROWS, BOARD_COLS))\n            self.winner = None\n            self.hashVal = None\n            self.end = None\n\n        def getHash(self):\n            if self.hashVal is None:\n                self.hashVal = 0\n                for i in self.data.reshape(BOARD_ROWS * BOARD_COLS):\n                    if i == -1:\n                        i = 2\n                    self.hashVal = self.hashVal * 3 + i\n            return int(self.hashVal)\n\n        def isEnd(self):\n            if self.end is not None:\n                return self.end\n            results = []\n            for i in range(0, BOARD_ROWS):\n                results.append(np.sum(self.data[i, :]))\n            for i in range(0, BOARD_COLS):\n                results.append(np.sum(self.data[:, i]))\n\n            results.append(0)\n            for i in range(0, BOARD_ROWS):\n                results[-1] += self.data[i, i]\n            results.append(0)\n            for i in range(0, BOARD_ROWS):\n                results[-1] += self.data[i, BOARD_ROWS - 1 - i]\n\n            for result in results:\n                if result == 3:\n                    self.winner = 1\n                    self.end = True\n                    return self.end\n                if result == -3:\n                    self.winner = -1\n                    self.end = True\n                    return self.end\n\n            sum = np.sum(np.abs(self.data))\n            if sum == BOARD_ROWS * BOARD_COLS:\n                self.winner = 0\n                self.end = True\n                return self.end\n\n            self.end = False\n            return self.end\n\n        def nextState(self, i, j, symbol):\n            newState = State()\n            newState.data = np.copy(self.data)\n            newState.data[i, j] = symbol\n            return newState\n\n        # print board\n        def show(self):\n            for i in range(0, BOARD_ROWS):\n                print('-------------')\n                out = '| '\n                for j in range(0, BOARD_COLS):\n                    if self.data[i, j] == 1:\n                        token = '*'\n                    if self.data[i, j] == 0:\n                        token = '0'\n                    if self.data[i, j] == -1:\n                        token = 'x'\n                    out += token + ' | '\n                print(out)\n            print('-------------')\n\n    def getAllStatesImpl(currentState, currentSymbol, allStates):\n        for i in range(0, BOARD_ROWS):\n            for j in range(0, BOARD_COLS):\n                if currentState.data[i][j] == 0:\n                    newState = currentState.nextState(i, j, currentSymbol)\n                    newHash = newState.getHash()\n                    if newHash not in allStates.keys():\n                        isEnd = newState.isEnd()\n                        allStates[newHash] = (newState, isEnd)\n                        if not isEnd:\n                            getAllStatesImpl(newState, -currentSymbol, allStates)\n\n    def getAllStates():\n        currentSymbol = 1\n        currentState = State()\n        allStates = dict()\n        allStates[currentState.getHash()] = (currentState, currentState.isEnd())\n        getAllStatesImpl(currentState, currentSymbol, allStates)\n        return allStates\n\n    allStates = getAllStates()\n\n    class Judger:\n        def __init__(self, player1, player2, feedback=True):\n            self.p1 = player1\n            self.p2 = player2\n            self.feedback = feedback\n            self.currentPlayer = None\n            self.p1Symbol = 1\n            self.p2Symbol = -1\n            self.p1.setSymbol(self.p1Symbol)\n            self.p2.setSymbol(self.p2Symbol)\n            self.currentState = State()\n            self.allStates = allStates\n\n        def giveReward(self):\n            if self.currentState.winner == self.p1Symbol:\n                self.p1.feedReward(1)\n                self.p2.feedReward(0)\n            elif self.currentState.winner == self.p2Symbol:\n                self.p1.feedReward(0)\n                self.p2.feedReward(1)\n            else:\n                self.p1.feedReward(0.1)\n                self.p2.feedReward(0.5)\n\n        def feedCurrentState(self):\n            self.p1.feedState(self.currentState)\n            self.p2.feedState(self.currentState)\n\n        def reset(self):\n            self.p1.reset()\n            self.p2.reset()\n            self.currentState = State()\n            self.currentPlayer = None\n\n        def play(self, show=False):\n            self.reset()\n            self.feedCurrentState()\n            while True:\n                if self.currentPlayer == self.p1:\n                    self.currentPlayer = self.p2\n                else:\n                    self.currentPlayer = self.p1\n                if show:\n                    self.currentState.show()\n                [i, j, symbol] = self.currentPlayer.takeAction()\n                self.currentState = self.currentState.nextState(i, j, symbol)\n                hashValue = self.currentState.getHash()\n                self.currentState, isEnd = self.allStates[hashValue]\n                self.feedCurrentState()\n                if isEnd:\n                    if self.feedback:\n                        self.giveReward()\n                    return self.currentState.winner\n\n    # AI player\n    class Player:\n        def __init__(self, stepSize = 0.1, exploreRate=0.1):\n            self.allStates = allStates\n            self.estimations = dict()\n            self.stepSize = stepSize\n            self.exploreRate = exploreRate\n            self.states = []\n\n        def reset(self):\n            self.states = []\n\n        def setSymbol(self, symbol):\n            self.symbol = symbol\n            for hash in self.allStates.keys():\n                (state, isEnd) = self.allStates[hash]\n                if isEnd:\n                    if state.winner == self.symbol:\n                        self.estimations[hash] = 1.0\n                    else:\n                        self.estimations[hash] = 0\n                else:\n                    self.estimations[hash] = 0.5\n\n        def feedState(self, state):\n            self.states.append(state)\n\n        def feedReward(self, reward):\n            if len(self.states) == 0:\n                return\n            self.states = [state.getHash() for state in self.states]\n            target = reward\n            for latestState in reversed(self.states):\n                value = self.estimations[latestState] + self.stepSize * (target - self.estimations[latestState])\n                self.estimations[latestState] = value\n                target = value\n            self.states = []\n\n        def takeAction(self):\n            state = self.states[-1]\n            nextStates = []\n            nextPositions = []\n            for i in range(BOARD_ROWS):\n                for j in range(BOARD_COLS):\n                    if state.data[i, j] == 0:\n                        nextPositions.append([i, j])\n                        nextStates.append(state.nextState(i, j, self.symbol).getHash())\n            if np.random.binomial(1, self.exploreRate):\n                np.random.shuffle(nextPositions)\n                self.states = []\n                action = nextPositions[0]\n                action.append(self.symbol)\n                return action\n\n            values = []\n            for hash, pos in zip(nextStates, nextPositions):\n                values.append((self.estimations[hash], pos))\n            np.random.shuffle(values)\n            values.sort(key=lambda x: x[0], reverse=True)\n            action = values[0][1]\n            action.append(self.symbol)\n            return action\n\n        def savePolicy(self):\n            fw = open('optimal_policy_' + str(self.symbol), 'wb')\n            pickle.dump(self.estimations, fw)\n            fw.close()\n\n        def loadPolicy(self):\n            fr = open('optimal_policy_' + str(self.symbol),'rb')\n            self.estimations = pickle.load(fr)\n            fr.close()\n            \n    # | 1 | 2 | 3 |\n    # | 4 | 5 | 6 |\n    # | 7 | 8 | 9 |\n    class HumanPlayer:\n        def __init__(self, stepSize = 0.1, exploreRate=0.1):\n            self.symbol = None\n            self.currentState = None\n            return\n        def reset(self):\n            return\n        def setSymbol(self, symbol):\n            self.symbol = symbol\n            return\n        def feedState(self, state):\n            self.currentState = state\n            return\n        def feedReward(self, reward):\n            return\n        def takeAction(self):\n            data = int(input(\"Input your position:\"))\n            data -= 1\n            i = data // int(BOARD_COLS)\n            j = data % BOARD_COLS\n            if self.currentState.data[i, j] != 0:\n                return self.takeAction()\n            return (i, j, self.symbol)\n\n    def train(epochs=20000):\n        player1 = Player()\n        player2 = Player()\n        judger = Judger(player1, player2)\n        player1Win = 0.0\n        player2Win = 0.0\n        for i in range(0, epochs):\n            print(\"Epoch\", i)\n            winner = judger.play()\n            if winner == 1:\n                player1Win += 1\n            if winner == -1:\n                player2Win += 1\n            judger.reset()\n        print(player1Win / epochs)\n        print(player2Win / epochs)\n        player1.savePolicy()\n        player2.savePolicy()\n\n    def compete(turns=500):\n        player1 = Player(exploreRate=0)\n        player2 = Player(exploreRate=0)\n        judger = Judger(player1, player2, False)\n        player1.loadPolicy()\n        player2.loadPolicy()\n        player1Win = 0.0\n        player2Win = 0.0\n        for i in range(0, turns):\n            print(\"Epoch\", i)\n            winner = judger.play()\n            if winner == 1:\n                player1Win += 1\n            if winner == -1:\n                player2Win += 1\n            judger.reset()\n        print(player1Win / turns)\n        print(player2Win / turns)\n\n    def play():\n        while True:\n            player1 = Player(exploreRate=0)\n            player2 = HumanPlayer()\n            judger = Judger(player1, player2, False)\n            player1.loadPolicy()\n            winner = judger.play(True)\n            if winner == player2.symbol:\n                print(\"Win!\")\n            elif winner == player1.symbol:\n                print(\"Lose!\")\n            else:\n                print(\"Tie!\")\n\n    train()\n    compete()\n    play()\n    \"\"\"\n```\n\n'\\n\\nBOARD_ROWS = 3\\nBOARD_COLS = 3\\nBOARD_SIZE = BOARD_ROWS * BOARD_COLS\\n\\nclass State:\\n    def __init__(self):\\n        self.data = np.zeros((BOARD_ROWS, BOARD_COLS))\\n        self.winner = None\\n        self.hashVal = None\\n        self.end = None\\n\\n    def getHash(self):\\n        if self.hashVal is None:\\n            self.hashVal = 0\\n            for i in self.data.reshape(BOARD_ROWS * BOARD_COLS):\\n                if i == -1:\\n                    i = 2\\n                self.hashVal = self.hashVal * 3 + i\\n        return int(self.hashVal)\\n\\n    def isEnd(self):\\n        if self.end is not None:\\n            return self.end\\n        results = []\\n        for i in range(0, BOARD_ROWS):\\n            results.append(np.sum(self.data[i, :]))\\n        for i in range(0, BOARD_COLS):\\n            results.append(np.sum(self.data[:, i]))\\n\\n        results.append(0)\\n        for i in range(0, BOARD_ROWS):\\n            results[-1] += self.data[i, i]\\n        results.append(0)\\n        for i in range(0, BOARD_ROWS):\\n            results[-1] += self.data[i, BOARD_ROWS - 1 - i]\\n\\n        for result in results:\\n            if result == 3:\\n                self.winner = 1\\n                self.end = True\\n                return self.end\\n            if result == -3:\\n                self.winner = -1\\n                self.end = True\\n                return self.end\\n\\n        sum = np.sum(np.abs(self.data))\\n        if sum == BOARD_ROWS * BOARD_COLS:\\n            self.winner = 0\\n            self.end = True\\n            return self.end\\n\\n        self.end = False\\n        return self.end\\n\\n    def nextState(self, i, j, symbol):\\n        newState = State()\\n        newState.data = np.copy(self.data)\\n        newState.data[i, j] = symbol\\n        return newState\\n\\n    # print board\\n    def show(self):\\n        for i in range(0, BOARD_ROWS):\\n            print(\\'-------------\\')\\n            out = \\'| \\'\\n            for j in range(0, BOARD_COLS):\\n                if self.data[i, j] == 1:\\n                    token = \\'*\\'\\n                if self.data[i, j] == 0:\\n                    token = \\'0\\'\\n                if self.data[i, j] == -1:\\n                    token = \\'x\\'\\n                out += token + \\' | \\'\\n            print(out)\\n        print(\\'-------------\\')\\n\\ndef getAllStatesImpl(currentState, currentSymbol, allStates):\\n    for i in range(0, BOARD_ROWS):\\n        for j in range(0, BOARD_COLS):\\n            if currentState.data[i][j] == 0:\\n                newState = currentState.nextState(i, j, currentSymbol)\\n                newHash = newState.getHash()\\n                if newHash not in allStates.keys():\\n                    isEnd = newState.isEnd()\\n                    allStates[newHash] = (newState, isEnd)\\n                    if not isEnd:\\n                        getAllStatesImpl(newState, -currentSymbol, allStates)\\n\\ndef getAllStates():\\n    currentSymbol = 1\\n    currentState = State()\\n    allStates = dict()\\n    allStates[currentState.getHash()] = (currentState, currentState.isEnd())\\n    getAllStatesImpl(currentState, currentSymbol, allStates)\\n    return allStates\\n\\nallStates = getAllStates()\\n\\nclass Judger:\\n    def __init__(self, player1, player2, feedback=True):\\n        self.p1 = player1\\n        self.p2 = player2\\n        self.feedback = feedback\\n        self.currentPlayer = None\\n        self.p1Symbol = 1\\n        self.p2Symbol = -1\\n        self.p1.setSymbol(self.p1Symbol)\\n        self.p2.setSymbol(self.p2Symbol)\\n        self.currentState = State()\\n        self.allStates = allStates\\n\\n    def giveReward(self):\\n        if self.currentState.winner == self.p1Symbol:\\n            self.p1.feedReward(1)\\n            self.p2.feedReward(0)\\n        elif self.currentState.winner == self.p2Symbol:\\n            self.p1.feedReward(0)\\n            self.p2.feedReward(1)\\n        else:\\n            self.p1.feedReward(0.1)\\n            self.p2.feedReward(0.5)\\n\\n    def feedCurrentState(self):\\n        self.p1.feedState(self.currentState)\\n        self.p2.feedState(self.currentState)\\n\\n    def reset(self):\\n        self.p1.reset()\\n        self.p2.reset()\\n        self.currentState = State()\\n        self.currentPlayer = None\\n\\n    def play(self, show=False):\\n        self.reset()\\n        self.feedCurrentState()\\n        while True:\\n            if self.currentPlayer == self.p1:\\n                self.currentPlayer = self.p2\\n            else:\\n                self.currentPlayer = self.p1\\n            if show:\\n                self.currentState.show()\\n            [i, j, symbol] = self.currentPlayer.takeAction()\\n            self.currentState = self.currentState.nextState(i, j, symbol)\\n            hashValue = self.currentState.getHash()\\n            self.currentState, isEnd = self.allStates[hashValue]\\n            self.feedCurrentState()\\n            if isEnd:\\n                if self.feedback:\\n                    self.giveReward()\\n                return self.currentState.winner\\n\\n# AI player\\nclass Player:\\n    def __init__(self, stepSize = 0.1, exploreRate=0.1):\\n        self.allStates = allStates\\n        self.estimations = dict()\\n        self.stepSize = stepSize\\n        self.exploreRate = exploreRate\\n        self.states = []\\n\\n    def reset(self):\\n        self.states = []\\n\\n    def setSymbol(self, symbol):\\n        self.symbol = symbol\\n        for hash in self.allStates.keys():\\n            (state, isEnd) = self.allStates[hash]\\n            if isEnd:\\n                if state.winner == self.symbol:\\n                    self.estimations[hash] = 1.0\\n                else:\\n                    self.estimations[hash] = 0\\n            else:\\n                self.estimations[hash] = 0.5\\n\\n    def feedState(self, state):\\n        self.states.append(state)\\n\\n    def feedReward(self, reward):\\n        if len(self.states) == 0:\\n            return\\n        self.states = [state.getHash() for state in self.states]\\n        target = reward\\n        for latestState in reversed(self.states):\\n            value = self.estimations[latestState] + self.stepSize * (target - self.estimations[latestState])\\n            self.estimations[latestState] = value\\n            target = value\\n        self.states = []\\n\\n    def takeAction(self):\\n        state = self.states[-1]\\n        nextStates = []\\n        nextPositions = []\\n        for i in range(BOARD_ROWS):\\n            for j in range(BOARD_COLS):\\n                if state.data[i, j] == 0:\\n                    nextPositions.append([i, j])\\n                    nextStates.append(state.nextState(i, j, self.symbol).getHash())\\n        if np.random.binomial(1, self.exploreRate):\\n            np.random.shuffle(nextPositions)\\n            self.states = []\\n            action = nextPositions[0]\\n            action.append(self.symbol)\\n            return action\\n\\n        values = []\\n        for hash, pos in zip(nextStates, nextPositions):\\n            values.append((self.estimations[hash], pos))\\n        np.random.shuffle(values)\\n        values.sort(key=lambda x: x[0], reverse=True)\\n        action = values[0][1]\\n        action.append(self.symbol)\\n        return action\\n\\n    def savePolicy(self):\\n        fw = open(\\'optimal_policy_\\' + str(self.symbol), \\'wb\\')\\n        pickle.dump(self.estimations, fw)\\n        fw.close()\\n\\n    def loadPolicy(self):\\n        fr = open(\\'optimal_policy_\\' + str(self.symbol),\\'rb\\')\\n        self.estimations = pickle.load(fr)\\n        fr.close()\\n        \\n# | 1 | 2 | 3 |\\n# | 4 | 5 | 6 |\\n# | 7 | 8 | 9 |\\nclass HumanPlayer:\\n    def __init__(self, stepSize = 0.1, exploreRate=0.1):\\n        self.symbol = None\\n        self.currentState = None\\n        return\\n    def reset(self):\\n        return\\n    def setSymbol(self, symbol):\\n        self.symbol = symbol\\n        return\\n    def feedState(self, state):\\n        self.currentState = state\\n        return\\n    def feedReward(self, reward):\\n        return\\n    def takeAction(self):\\n        data = int(input(\"Input your position:\"))\\n        data -= 1\\n        i = data // int(BOARD_COLS)\\n        j = data % BOARD_COLS\\n        if self.currentState.data[i, j] != 0:\\n            return self.takeAction()\\n        return (i, j, self.symbol)\\n\\ndef train(epochs=20000):\\n    player1 = Player()\\n    player2 = Player()\\n    judger = Judger(player1, player2)\\n    player1Win = 0.0\\n    player2Win = 0.0\\n    for i in range(0, epochs):\\n        print(\"Epoch\", i)\\n        winner = judger.play()\\n        if winner == 1:\\n            player1Win += 1\\n        if winner == -1:\\n            player2Win += 1\\n        judger.reset()\\n    print(player1Win / epochs)\\n    print(player2Win / epochs)\\n    player1.savePolicy()\\n    player2.savePolicy()\\n\\ndef compete(turns=500):\\n    player1 = Player(exploreRate=0)\\n    player2 = Player(exploreRate=0)\\n    judger = Judger(player1, player2, False)\\n    player1.loadPolicy()\\n    player2.loadPolicy()\\n    player1Win = 0.0\\n    player2Win = 0.0\\n    for i in range(0, turns):\\n        print(\"Epoch\", i)\\n        winner = judger.play()\\n        if winner == 1:\\n            player1Win += 1\\n        if winner == -1:\\n            player2Win += 1\\n        judger.reset()\\n    print(player1Win / turns)\\n    print(player2Win / turns)\\n\\ndef play():\\n    while True:\\n        player1 = Player(exploreRate=0)\\n        player2 = HumanPlayer()\\n        judger = Judger(player1, player2, False)\\n        player1.loadPolicy()\\n        winner = judger.play(True)\\n        if winner == player2.symbol:\\n            print(\"Win!\")\\n        elif winner == player1.symbol:\\n            print(\"Lose!\")\\n        else:\\n            print(\"Tie!\")\\n\\ntrain()\\ncompete()\\nplay()\\n'"
  },
  {
    "objectID": "chapter2.html#kæœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "href": "chapter2.html#kæœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "title": "ç¬¬ï¼’ç« å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "section": "kæœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "text": "kæœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ\n\\(k\\)å€‹ã®é¸æŠè‚¢ãŒã‚ã‚Šã€ã©ã‚Œã‹1ã¤ã‚’é¸ã¶ã¨é¸æŠã«ä¾å­˜ã—ãŸå®šå¸¸ç¢ºç‡åˆ†å¸ƒã‹ã‚‰å ±é…¬ãŒç™ºç”Ÿã™ã‚‹ã€‚ã“ã‚Œã‚’ç¹°ã‚Šè¿”ã—ã€ã‚ã‚‹æ±ºã‚ã‚‰ã‚ŒãŸæ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã«ãŠã„ã¦æœŸå¾…åˆè¨ˆå ±é…¬ã‚’æœ€å¤§åŒ–ã™ã‚‹å•é¡Œã‚’\\(k\\)æœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã¨ã„ã†ã€‚ä»¥å¾Œã€æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—tã§é¸æŠã•ã‚ŒãŸè¡Œå‹•ã‚’\\(A_t\\)ã€å¯¾å¿œã™ã‚‹å ±é…¬ã‚’\\(R_t\\)ã¨ã™ã‚‹ã€‚\\(a\\)ãŒé¸æŠã•ã‚ŒãŸæ™‚ã®ç¢ºç‡å¤‰æ•°ã‚’\\(X_a\\)ã¨ã™ã‚‹ã¨ã€\\(a\\)ãŒé¸æŠã•ã‚ŒãŸã¨ãã®æœŸå¾…å ±é…¬\\(q_*(a)\\)ã‚’æ¬¡ã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ã€‚\n\\[\nq_*(a):=ğ”¼[X_a]\n\\]\næ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—tã®è¡Œå‹•aã®ä¾¡å€¤ã®æ¨å®šå€¤ã‚’\\(Q_t(a)\\)ã¨ã™ã‚‹ã€‚ã“ã‚Œã‚’\\(q_*(a)\\)ã«è¿‘ã¥ã‘ãŸã„ã€‚ æ¨å®šä¾¡å€¤ãŒæœ€å¤§ã¨ãªã‚‹è¡Œå‹•ã‚’ã‚°ãƒªãƒ¼ãƒ‡ã‚£è¡Œå‹•ã¨ã„ã„ã€çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦ã„ã‚‹ã¨ã„ã†ã€‚ãã†ã§ãªã„ã¨ãã¯æ¢ç´¢ã—ã¦ã„ã‚‹ã¨ã„ã†ã€‚"
  },
  {
    "objectID": "chapter2.html#è¡Œå‹•ä¾¡å€¤æ‰‹æ³•",
    "href": "chapter2.html#è¡Œå‹•ä¾¡å€¤æ‰‹æ³•",
    "title": "ç¬¬ï¼’ç« å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "section": "è¡Œå‹•ä¾¡å€¤æ‰‹æ³•",
    "text": "è¡Œå‹•ä¾¡å€¤æ‰‹æ³•\nè¡Œå‹•ä¾¡å€¤ã®æ¨å®šã‚’ã™ã‚‹æ–¹æ³•ã®ç·ç§°ã‚’è¡Œå‹•ä¾¡å€¤æ‰‹æ³•ã¨ã„ã†ã€‚è¡Œå‹•ä¾¡å€¤ã‚’æ¨å®šã™ã‚‹è‡ªç„¶ãªæ–¹æ³•ã¨ã—ã¦ã€å®Ÿéš›ã«å¾—ã‚‰ã‚ŒãŸå ±é…¬ã‚’å¹³å‡ã™ã‚‹ã“ã¨ãŒæŒ™ã’ã‚‰ã‚Œã‚‹ã€‚\n\\[\nQ_t(a):= \\frac{tã‚ˆã‚Šå‰ã«aã‚’è¡Œã£ãŸã¨ãã®å ±é…¬ã®åˆè¨ˆ}{tã®å‰ã¾ã§ã«aã‚’è¡Œã£ãŸå›æ•°}=\\frac{\\sum_{i=1}^{t-1}R_iï½¥ğŸ™_{A_i=a}}{\\sum_{i=1}^{t-1}ğŸ™_{A_i=a}}\n\\]\nãŸã ã—\\(ğŸ™_{æ¡ä»¶}\\)ã¯æ¡ä»¶ãŒçœŸã®ã¨ã1ã€å½ã®ã¨ã0ã‚’ã¨ã‚‹ã‚‚ã®ã¨ã™ã‚‹ã€‚ã“ã‚Œã‚’è¡Œå‹•ä¾¡å€¤æ¨å®šã®ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒ«å¹³å‡æ³•ã¨ã„ã†ã€‚æ¯å›æœ€ã‚‚æ¨å®šä¾¡å€¤ãŒé«˜ã„è¡Œå‹•ã‚’ã™ã‚‹ã‚°ãƒªãƒ¼ãƒ‡ã‚£è¡Œå‹•é¸æŠæ³•ã¯æ¬¡å¼ã§è¡¨ã•ã‚Œã‚‹ã€‚\n\\[\nA_t=\\text{arg max}_aQ_t(a)\n\\]\nãŸã ã—\\(\\text{arg max}_a\\)ã¯\\(Q_t(a)\\)ãŒæœ€å¤§ã¨ãªã‚‹ã‚ˆã†ãª\\(a\\)ã‚’ã‹ãˆã™ã€‚ã“ã‚Œã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ã€æ¢ç´¢ã‚’è¡Œã‚ã›ã‚‹ãŸã‚ã«æ¯å›ç¢ºç‡\\(\\epsilon\\)ã§ãƒ©ãƒ³ãƒ€ãƒ ãªé¸æŠã‚’è¡Œã‚ã›ã‚‹æ‰‹æ³•ã‚’\\(\\epsilon\\)-ã‚°ãƒªãƒ¼ãƒ‡ã‚£æ³•ã¨ã„ã†ã€‚"
  },
  {
    "objectID": "chapter2.html#æœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã«ã‚ˆã‚‹å®Ÿé¨“",
    "href": "chapter2.html#æœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã«ã‚ˆã‚‹å®Ÿé¨“",
    "title": "ç¬¬ï¼’ç« å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "section": "10æœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã«ã‚ˆã‚‹å®Ÿé¨“",
    "text": "10æœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã«ã‚ˆã‚‹å®Ÿé¨“\n2000å€‹ã®kæœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã‚’ã€k=10ã¨ã—ã€æ¬¡ã®ã‚ˆã†ã«ãƒ©ãƒ³ãƒ€ãƒ ã«ç”Ÿæˆã™ã‚‹ï¼šå„\\(q_*(a)\\)ã¯æ¨™æº–æ­£è¦åˆ†å¸ƒ(\\(N(0,1)\\))ã«å¾“ã£ã¦ç”Ÿæˆã—ã€å„\\(X_a\\)ã¯æ­£è¦åˆ†å¸ƒ\\(N(q_*(a),1)\\)ã«å¾“ã†ã¨ã™ã‚‹ã€‚å„åˆæœŸæ¨å®šå€¤\\(Q_1(a)\\)ã¯0ã¨ã™ã‚‹ã€‚å„å•é¡Œã§ã€1000ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡Œã‚’1å›ã®è©¦è¡Œã¨ã™ã‚‹ã€‚\n2000å€‹ã®å•é¡Œãã‚Œãã‚Œã«å¯¾ã—ã‚°ãƒªãƒ¼ãƒ‡ã‚£æ³•ã¨äºŒã¤ã®\\(\\epsilon\\)-ã‚°ãƒªãƒ¼ãƒ‡ã‚£æ³•ã‚’è©¦è¡Œã—ã€2000å›ç¹°ã‚Šè¿”ã—å¹³å‡ã‚’ã¨ã£ãŸçµæœã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚‹ã€‚\n\nå›³ã‹ã‚‰\\(\\epsilon=0.1\\)ã®ã¨ãã¯\\(\\epsilon=0.01\\)ã®ã¨ãã‚ˆã‚Šã‚‚ç´ æ—©ãæœ€é©è¡Œå‹•ã‚’ã¨ã‚Œã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ãŒã€è¶…é•·æœŸçš„ãªæ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã§ã¿ã‚Œã°æœ€çµ‚çš„ã«ã¯\\(\\epsilon=0.01\\)ã®ã¨ãã®æ–¹ãŒè‰¯ã„çµæœã‚’ç¤ºã™ã ã‚ã†ã¨ã„ã†ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚"
  },
  {
    "objectID": "chapter2.html#é€æ¬¡çš„å®Ÿè£…",
    "href": "chapter2.html#é€æ¬¡çš„å®Ÿè£…",
    "title": "ç¬¬ï¼’ç« å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "section": "é€æ¬¡çš„å®Ÿè£…",
    "text": "é€æ¬¡çš„å®Ÿè£…\nã‚µãƒ³ãƒ—ãƒ«å¹³å‡ã®è¨ˆç®—ãŒã©ã®ã‚ˆã†ã«ç°¡ç•¥åŒ–ã§ãã‚‹ã®ã‹ã‚’ç´¹ä»‹ã™ã‚‹ã€‚ç°¡å˜ã®ãŸã‚ã€1æœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã§ã®ã‚µãƒ³ãƒ—ãƒ«å¹³å‡ã‚’è€ƒãˆã‚‹ã€‚ã‚¹ãƒ†ãƒƒãƒ—\\(n\\)æ™‚ã®æ¨å®šå ±é…¬\\(Q_n\\)ã¯æ¬¡å¼ã§è¡¨ã•ã‚Œã‚‹ã€‚\n\\[\nQ_n:=\\frac{R_1+R_2+ï½¥ï½¥ï½¥+R_n}{n-1}\n\\]\nå„\\(R_n\\)ã‚’è¨˜éŒ²ã—ã¦æ¯å›\\(Q_n\\)ã‚’æ±‚ã‚ã‚‹ã‚„ã‚Šæ–¹ã¯å¿…è¦ãƒ¡ãƒ¢ãƒªã¨è¨ˆç®—é‡ãŒå¢—å¤§ã—ã¦ã—ã¾ã†ãŒã€å®Ÿéš›ã¯æ¬¡å¼ã®ã‚ˆã†ã«é€ä¸€æ›´æ–°ã§ãã‚‹ã€‚\n\\[\nQ_{n+1}=\\frac{1}{n}\\sum_{i=1}^{n}R_i\\\\ =\\frac{1}{n}(R_n+\\sum_{i=1}^{n-1}R_i)\\\\ =\\frac{1}{n}(R_n+(n-1)Q_n)\\\\ =Q_n+\\frac{1}{n}(R_n-Q_n)\n\\]\nã“ã†ã™ã‚Œã°ãƒ¡ãƒ¢ãƒªã¯\\(Q_n\\)ã¨\\(n\\)ã®åˆ†ã ã‘ã§è‰¯ãã€è¨ˆç®—é‡ã‚‚æœ€å¾Œã®å¼ã®ã¿ã§è‰¯ããªã‚‹ã€‚ã“ã‚Œã®ä¸€èˆ¬å½¢ã¯æ¬¡å¼ã§è¡¨ã•ã‚Œã‚‹ã€‚\n\\[\nNewEstimate \\leftarrow OldEstimate + StepSize\\ [Target - OldEstimate]\n\\]\n\\([Target - OldEstimate]\\)ã¯æ¨å®šã®èª¤å·®ã‚’è¡¨ã—ã¦ã„ã‚‹ã€‚ã‚¹ãƒ†ãƒƒãƒ—ãŒé€²ã‚€ã«ã¤ã‚Œæ¨å®šã¯\\(Target\\)(ä»Šå›ã¯\\(n\\)ç•ªç›®ã®å ±é…¬)ã«è¿‘ã¥ã„ã¦ã„ãã€‚ä»Šå›ã§ã¯\\(StepSize\\)ã¯\\(1/n\\)ã¨ä¸€å®šã ãŒã€ã‚¹ãƒ†ãƒƒãƒ—ã«å¿œã˜ã¦å¤‰å‹•ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã€‚ä»¥å¾Œã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’\\(\\alpha\\)ã‚„\\(\\alpha_t(a)\\)ã¨è¡¨ã™ã€‚\né€æ¬¡çš„è¨ˆç®—ã«ã‚ˆã‚‹ã‚µãƒ³ãƒ—ãƒ«å¹³å‡ã¨\\(\\epsilon\\)-è¡Œå‹•é¸æŠã‚’ä½¿ã£ãŸkæœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚‹ã€‚"
  },
  {
    "objectID": "chapter2.html#éå®šå¸¸å•é¡Œã‚’èª¿ã¹ã‚‹",
    "href": "chapter2.html#éå®šå¸¸å•é¡Œã‚’èª¿ã¹ã‚‹",
    "title": "ç¬¬ï¼’ç« å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "section": "éå®šå¸¸å•é¡Œã‚’èª¿ã¹ã‚‹",
    "text": "éå®šå¸¸å•é¡Œã‚’èª¿ã¹ã‚‹\néå®šå¸¸çš„ãªå•é¡Œã€ã™ãªã‚ã¡ã€è¡Œå‹•ã«å¯¾ã™ã‚‹å ±é…¬(ã¤ã¾ã‚Š\\(X_a\\))ãŒæ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«å¤‰åŒ–ã™ã‚‹å•é¡Œã®å ´åˆã«ã¤ã„ã¦ã¯,ã€æ–°ã—ã„å ±é…¬ã®æ–¹ã«é‡ã¿ã‚’ã¤ã‘ã‚‹æ–¹ãŒç†ã«ã‹ãªã£ã¦ã„ã‚‹ã€‚ãã“ã§ã€é€æ¬¡æ›´æ–°å‰‡ã¯å®šæ•°\\(\\alpha \\in (0,1]\\)ã‚’ç”¨ã„ã¦æ¬¡ã®ã‚ˆã†ã«ä¿®æ­£ã•ã‚Œã‚‹ã€‚\n\\[\nQ_{n+1}:=Q_n+\\alpha[R_n-Q_n]\n\\]\nã“ã‚Œã«ã‚ˆã‚Š\\(Q_{n+1}\\)ã¯æ¬¡ã®ã‚ˆã†ã«å¤‰å½¢ã§ãã‚‹ã€‚\n\\[\nQ_{n+1}=Q_n+\\alpha[R_n-Q_n] \\\\\\\\\n=\\alpha R_n+(1-\\alpha)Q_n \\\\\\\\\n=\\alpha R_n+(1-\\alpha)[\\alpha R_{n-1}+(1-\\alpha)Q_{n-1}] \\\\\\\\\n=\\alpha R_n+(1-\\alpha)\\alpha R_{n-1}+(1-\\alpha)^2Q_{n-1} \\\\\\\\\nã“ã‚Œã‚’ç¹°ã‚Šè¿”ã— \\\\\\\\\n=(1-a)^nQ_1+\\sum_{i-1}^{n}\\alpha(1-\\alpha)^{n-i}R_i\n\\]\n\\((1-a)^n+\\sum_{i-1}^{n}\\alpha(1-\\alpha)^{n-i}=1\\)ã‚ˆã‚Šã€\\(Q_{n+1}\\)ã¯éå»ã®å ±é…¬ã¨åˆæœŸã®æ¨å®šå€¤\\(Q_1\\)ã®åŠ é‡å¹³å‡ã§ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚é‡ã¿ã¯\\(1-\\alpha\\)ã®å†ªä¹—ã«å¾“ã£ã¦æŒ‡æ•°çš„ã«æ¸›è¡°ã—ã¦ã„ããŸã‚ã€ã“ã®åŠ é‡å¹³å‡ã‚’æŒ‡æ•°ç›´è¿‘æ€§åŠ é‡å¹³å‡ã¨ã‚‚ã„ã†ã€‚\n\\(\\alpha\\)ã‚’ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«å¤‰å‹•ã•ã›ã‚‹ã¨ä¾¿åˆ©ãªã“ã¨ã‚‚ã‚ã‚‹ã€‚è¡Œå‹•aãŒnç•ªç›®ã«é¸æŠã•ã‚ŒãŸã¨ãã®ã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’\\(\\alpha_n(a)\\)ã¨è¡¨ã™ã€‚å®šå¸¸çš„ãªå•é¡Œã«ãŠã„ã¦ã¯ã€ç¢ºç‡è¿‘ä¼¼ç†è«–ã‚ˆã‚Šã€æ¨å®šè¡Œå‹•ä¾¡å€¤ãŒçœŸã®è¡Œå‹•ä¾¡å€¤ã«ç¢ºç‡1ã§åæŸã™ã‚‹å¿…è¦ååˆ†æ¡ä»¶ã¯æ¬¡ã®é€šã‚Šã§ã‚ã‚‹ã€‚\n\\[\n\\sum_{n=1}^{\\infty}\\alpha_n(a)=\\infty\\ ã‹ã¤\\ \\sum_{n=1}^{\\infty}\\alpha_n^2(a)<\\infty\n\\]\nã—ã‹ã—å®Ÿç”¨ã§ã¯éå®šå¸¸å•é¡Œã‚’æ‰±ã†äº‹ãŒå¤šã„ã®ã§ã€ä¸Šå¼ã‚’æº€ãŸã™ã‚¹ãƒ†ãƒƒãƒ—ã‚µã‚¤ã‚ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ç†è«–ç ”ç©¶ã§ã¯å¤šç”¨ã•ã‚Œã‚‹ãŒã€å¿œç”¨ã‚„å®Ÿé¨“ç ”ç©¶ã§ã¯ã‚ã£ãŸã«ä½¿ç”¨ã•ã‚Œãªã„ã€‚\n\n```{python}\nprint(\"Hello Python!\")\n```\n\nHello Python!"
  },
  {
    "objectID": "chapter2.html#æ¥½è¦³çš„åˆæœŸå€¤",
    "href": "chapter2.html#æ¥½è¦³çš„åˆæœŸå€¤",
    "title": "ç¬¬ï¼’ç« å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "section": "æ¥½è¦³çš„åˆæœŸå€¤",
    "text": "æ¥½è¦³çš„åˆæœŸå€¤\nã“ã“ã¾ã§ã®æ‰‹æ³•ã¯åˆæœŸæ¨å®šå€¤\\(Q_1(a)\\)ã«ã‚ã‚‹ç¨‹åº¦ä¾å­˜ã™ã‚‹ã€‚ã“ã®ã“ã¨ã‚’åˆæœŸæ¨å®šå€¤ã«ã¤ã„ã¦ãƒã‚¤ã‚¢ã‚¹ãŒã‚ã‚‹ã¨ã„ã†ã€‚\n10æœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã«ã‚ˆã‚‹å®Ÿé¨“ã§ã€è¡Œå‹•ä¾¡å€¤ã®åˆæœŸæ¨å®šå€¤\\(Q_1(a)\\)ã‚’\\(0\\)ã§ã¯ãªã\\(+5\\)ã¨ã™ã‚‹ã€‚\\(q_*(a)\\)ã¯æ¨™æº–æ­£è¦åˆ†å¸ƒã‹ã‚‰é¸æŠã•ã‚Œã‚‹ã“ã¨ã‚’è€ƒãˆã‚‹ã¨æ¥½è¦³çš„ã§ã‚ã‚‹ï¼ˆ\\(q_*(a)\\)ãŒ\\(+5\\)ä»¥ä¸Šã¨ãªã‚‹ç¢ºç‡ã¯ç´„\\(2.87\\times10^{-7}\\)ï¼‰ã€‚ã‚ˆã£ã¦æœ€åˆã«è¡Œå‹•ãŒé¸æŠã•ã‚ŒãŸå¾Œã€å¾—ã‚‰ã‚ŒãŸå ±é…¬ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯å¤±æœ›ã—ã¦åˆ¥ã®è¡Œå‹•ã‚’ã™ã‚‹ã€‚ã“ã®ã‚ˆã†ã«ã—ã¦æ¢ç´¢ã‚’ä¿ƒã™åˆæœŸå€¤ã‚’æ¥½è¦³çš„åˆæœŸå€¤ã¨ã„ã†ã€‚\n10æœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã«ã‚ˆã‚‹å®Ÿé¨“ã§ã€å„\\(Q_1(a)\\)ã‚’\\(+5\\)ã¨ã—ãŸå ´åˆã®ã‚°ãƒªãƒ¼ãƒ‡ã‚£æ³•ã¨ã€å„\\(Q_1(a)\\)ã‚’\\(0\\)ã¨ã—ãŸå ´åˆã®\\(\\epsilon\\)-ã‚°ãƒªãƒ¼ãƒ‡ã‚£æ³•ã®æ¯”è¼ƒã‚’ä»¥ä¸‹ã«ç¤ºã™ã€‚\n\nã—ã‹ã—ã“ã®æ‰‹æ³•ã‚‚æ¢ç´¢ã¯ä¸€æ™‚çš„ã«ã—ã‹ä¿ƒé€²ã•ã‚Œãªã„ãŸã‚ã€éå®šå¸¸å•é¡Œã«ã¯ã‚ã¾ã‚Šé©ã•ãªã„ã€‚"
  },
  {
    "objectID": "chapter2.html#ä¸Šé™ä¿¡é ¼åŒºé–“è¡Œå‹•é¸æŠ",
    "href": "chapter2.html#ä¸Šé™ä¿¡é ¼åŒºé–“è¡Œå‹•é¸æŠ",
    "title": "ç¬¬ï¼’ç« å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "section": "ä¸Šé™ä¿¡é ¼åŒºé–“è¡Œå‹•é¸æŠ",
    "text": "ä¸Šé™ä¿¡é ¼åŒºé–“è¡Œå‹•é¸æŠ\n\\(\\epsilon\\)-ã‚°ãƒªãƒ¼ãƒ‡ã‚£æ³•ã§ã®æ¢ç´¢ã¯è¡Œå‹•ãŒãƒ©ãƒ³ãƒ€ãƒ ãŒé¸ã°ã‚Œã‚‹ãŒã€å®Ÿéš›ã«æœ€é©è¡Œå‹•ã§ã‚ã‚‹å¯èƒ½æ€§ã«å¿œã˜ã¦æ¢ç´¢ã‚’è¡Œã†ã»ã†ãŒæœ›ã¾ã—ã„ã€‚ã™ãªã‚ã¡ã€æ¨å®šå€¤åŠã³ãã®æ¨å®šå€¤ã®ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ã¦é¸æŠã™ã‚Œã°è‰¯ã„ã€‚ä¾‹ãˆã°æ¬¡å¼ã«å¾“ã£ã¦è¡Œå‹•ã™ã‚‹ã“ã¨ãŒæŒ™ã’ã‚‰ã‚Œã‚‹ã€‚\n\\[\nA_t:=\\text{arg max}_a\\Bigg(Q_t(a)+c\\sqrt{\\frac{\\log_e t}{N_t(a)}}\\Bigg)\n\\]\n\\(N_t(a)\\)ã¯æ™‚åˆ»\\(t\\)ã¾ã§ã«è¡Œå‹•\\(a\\)ãŒé¸æŠã•ã‚ŒãŸå›æ•°ã€\\(c>0\\)ã¯æ¢ç´¢ã‚’åˆ¶å¾¡ã™ã‚‹æ•°ã§ã‚ã‚‹ã€‚ã“ã‚Œã‚’ä¸Šé™ä¿¡é ¼åŒºé–“è¡Œå‹•é¸æŠï¼ˆUCBï¼‰ã¨ã„ã†ã€‚UCBã‚’ç”¨ã„ãŸ10æœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã«ã‚ˆã‚‹å®Ÿé¨“çµæœã‚’ä»¥ä¸‹ã«ç¤ºã™ã€‚\n å¤šãã®å ´åˆã§UCBã¯è‰¯ã„æ€§èƒ½ã‚’ç¤ºã™ãŒã€\\(\\epsilon\\)-ã‚°ãƒªãƒ¼ãƒ‡ã‚£ã¨æ¯”ã¹ã‚‹ã¨ã€ä¸€èˆ¬çš„ãªå¼·åŒ–å­¦ç¿’ã«æ‹¡å¼µã—ã¦ç”¨ã„ã‚‹ã“ã¨ã¯è¨ˆç®—ã‚„è¿‘ä¼¼ã®é¢ã«ãŠã„ã¦å›°é›£ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ã®ã§ã€é€šå¸¸ã¯å®Ÿç”¨çš„ã§ãªã„ã€‚"
  },
  {
    "objectID": "chapter2.html#å‹¾é…ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ",
    "href": "chapter2.html#å‹¾é…ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ",
    "title": "ç¬¬ï¼’ç« å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "section": "å‹¾é…ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ",
    "text": "å‹¾é…ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ \næœ¬ç« ã§ã¯æ¨å®šè¡Œå‹•ä¾¡å€¤ã‚’è¡Œå‹•é¸æŠã«ç”¨ã„ã¦ããŸã€‚ã—ã‹ã—ä»–ã«ã‚‚ã‚„ã‚Šæ–¹ã¯ã‚ã‚‹ã€‚å„è¡Œå‹•\\(a\\)ã«å¯¾ã—ã¦æ•°å€¤çš„ã«è¡¨ã•ã‚Œã‚‹å„ªå…ˆåº¦ï¼ˆ\\(H_t(a)\\)ã¨è¡¨ã™ï¼‰ã‚’å­¦ç¿’ã™ã‚‹æ–¹æ³•ã‚’è€ƒãˆã‚‹ã€‚è¡Œå‹•ç¢ºç‡ã¯æ¬¡ã®ã‚ˆã†ãªã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹åˆ†å¸ƒã«å¾“ã†ã€‚\n\\[\n\\text{Pr}\\{A_t=a\\}:=\\pi_t(a):=\\frac{e^{H_t(a)}}{\\sum_{b=1}^{k}e^{H_t(b)}}\n\\]\nã“ã“ã§ã¯æ™‚åˆ»\\(t\\)ã«è¡Œå‹•\\(a\\)ã‚’ã¨ã‚‹ç¢ºç‡ã‚’\\(\\pi_t(a)\\)ã¨è¡¨ã™ã¨ã™ã‚‹ã€‚ã¾ãŸåˆæœŸçŠ¶æ…‹ã§ã¯å…¨ã¦ã®è¡Œå‹•ã®å„ªå…ˆåº¦ã‚’åŒã˜ã¨ã™ã‚‹ã€‚\nç¢ºç‡çš„å‹¾é…ä¸Šæ˜‡æ³•ã«åŸºã¥ã„ã¦è‡ªç„¶ã«å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è¨­å®šã™ã‚‹ã¨ã€è¡Œå‹•\\(A_t\\)ã§å ±é…¬\\(R_t\\)ã‚’å—ã‘å–ã£ãŸå¾Œã€è¡Œå‹•å„ªå…ˆåº¦ã¯æ¬¡ã®ã‚ˆã†ã«æ›´æ–°ã•ã‚Œã‚‹ã€‚\n\\[\nH_{t+1}(A_t)=H_t(A_t)+\\alpha(R_t-\\overline R_t)(1-\\pi_t(A_t)),\\\\\\\\\nH_{t+1}(a):=H_t(A_t)+\\alpha(R_t-\\overline R_t)\\pi(a)\\ \\ ( a\\neq A_t)\n\\]\nãŸã ã—\\(\\overline R_t\\)ï¼ˆã“ã“ã§ã¯ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã„ã†ï¼‰ã¯æ™‚åˆ»tã¾ã§ã®å…¨ã¦ã®å ±é…¬ã®å¹³å‡ã§ã‚ã‚‹ã€‚\nä¾‹ãˆã°kæœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã«ãŠã„ã¦ã€\\(q_*(a)\\)ãŒå¹³å‡\\(+4\\)ã€åˆ†æ•£\\(1\\)ã®æ­£è¦åˆ†å¸ƒã‹ã‚‰é¸æŠã•ã‚Œã‚‹ã¨ã™ã‚‹ã€‚å ±é…¬å…¨ä½“ã®å€¤ãŒå¤§ãããªã£ã¦ã‚‚ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãŒãã‚Œã«å¿œã˜ã¦å¢—åŠ ã™ã‚‹ã®ã§å‹¾é…ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã¯å…¨ãå½±éŸ¿ã—ãªã„ã€‚ã—ã‹ã—ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’è€ƒæ…®ã—ãªã„ï¼ˆ\\(\\overline R_t\\)=0ã¨ã™ã‚‹ï¼‰ã¨æ¬¡ã®å›³ã‹ã‚‰ã‚‚åˆ†ã‹ã‚‹ã‚ˆã†ã«æ€§èƒ½ã¯å¤§å¹…ã«ä½ä¸‹ã™ã‚‹ã€‚"
  },
  {
    "objectID": "chapter2.html#é€£æƒ³æ¢ç´¢æ–‡è„ˆä»˜ããƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆ",
    "href": "chapter2.html#é€£æƒ³æ¢ç´¢æ–‡è„ˆä»˜ããƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆ",
    "title": "ç¬¬ï¼’ç« å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "section": "é€£æƒ³æ¢ç´¢ï¼ˆæ–‡è„ˆä»˜ããƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆï¼‰",
    "text": "é€£æƒ³æ¢ç´¢ï¼ˆæ–‡è„ˆä»˜ããƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆï¼‰\nç¬¬äºŒç« ã§ã¯çŠ¶æ³ã«å¿œã˜ã¦ç•°ãªã‚‹è¡Œå‹•ã‚’ã¨ã‚‰ã›ã‚‹å¿…è¦ã®ãªã„ã‚ˆã†ãªéé€£æƒ³çš„ãªã‚¿ã‚¹ã‚¯ã®ã¿ã‚’è€ƒãˆã¦ããŸã€‚ã—ã‹ã—ä¸€èˆ¬ã®å¼·åŒ–å­¦ç¿’ã®ã‚¿ã‚¹ã‚¯ã§ã¯è¤‡æ•°ã®çŠ¶æ³ãŒã‚ã‚Šã€æ–¹ç­–ã€ã™ãªã‚ã¡ã‚ã‚‹çŠ¶æ…‹ã§ã®ãã“ã‹ã‚‰ã¨ã‚‹ã¹ãè¡Œå‹•ã¸ã®å†™åƒã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã‚’ç›®æ¨™ã¨ã™ã‚‹ã€‚\nä¾‹ãˆã°ã€è¤‡æ•°ã®kæœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œï¼ˆã‚¿ã‚¹ã‚¯ï¼‰ãŒã‚ã‚Šã€å„ã‚¹ãƒ†ãƒƒãƒ—ã§ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’è¡Œã†ã¨ã™ã‚‹ã€‚ã“ã‚Œã¯å˜ä¸€ã®éå®šå¸¸ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã¨ã—ã¦è€ƒãˆã‚‹ã“ã¨ãŒã§ãã‚‹ãŒã€ã“ã‚Œã ã‘ã ã¨è§£ã‚’å¾—ã‚‹ã®ãŒå›°é›£ã§ã‚ã‚‹ã€‚ãã“ã§å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã©ã®ã‚¿ã‚¹ã‚¯ãŒé¸ã°ã‚ŒãŸã‹ã‚’ç¤ºã™æ‰‹ãŒã‹ã‚Šï¼ˆã‚¿ã‚¹ã‚¯ã‚’åŒºåˆ¥ã™ã‚‹æƒ…å ±ï¼‰ã‚’å¾—ã‚‹ã¨ã™ã‚‹ã€‚ã“ã®å ´åˆã ã¨ã‚¿ã‚¹ã‚¯ã«å¿œã˜ãŸè¡Œå‹•ã‚’å­¦ç¿’ã§ãã‚‹ã€‚ã“ã®ã‚ˆã†ãªå•é¡Œã‚’é€£æƒ³æ¢ç´¢ã‚„æ–‡è„ˆä»˜ããƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆã¨ã„ã†ã€‚"
  },
  {
    "objectID": "chapter2.html#ã¾ã¨ã‚",
    "href": "chapter2.html#ã¾ã¨ã‚",
    "title": "ç¬¬ï¼’ç« å¤šè…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œ",
    "section": "ã¾ã¨ã‚",
    "text": "ã¾ã¨ã‚\nã“ã‚Œã¾ã§ã®æ‰‹æ³•ã®kæœ¬è…•ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆå•é¡Œã«ãŠã‘ã‚‹æ€§èƒ½ã‚’ä»¥ä¸‹ã«ç¤ºã™ã€‚\\(x\\)è»¸ã§ã¯å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€¤(\\(\\epsilon\\)ã€\\(\\alpha\\)ã€\\(c\\)ã€æ¥½è¦³çš„åˆæœŸå€¤\\(Q_0\\))ãŒå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã§ã¨ã‚‰ã‚Œã¦ã„ã‚‹ã“ã¨ã«æ³¨æ„ã€‚"
  },
  {
    "objectID": "chapter3.html#ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ç’°å¢ƒã®å¢ƒç•Œ",
    "href": "chapter3.html#ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ç’°å¢ƒã®å¢ƒç•Œ",
    "title": "ç¬¬ï¼“ç«  æœ‰é™ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹",
    "section": "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ç’°å¢ƒã®å¢ƒç•Œ",
    "text": "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ç’°å¢ƒã®å¢ƒç•Œ\nå„ã‚¹ãƒ†ãƒƒãƒ—\\(t\\)ã”ã¨ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ç’°å¢ƒã®çŠ¶æ…‹\\(S\\)ã‚’ã‚‚ã¨ã«è¡Œå‹•\\(A\\)ã‚’é¸æŠã™ã‚‹ã€‚1ã‚¹ãƒ†ãƒƒãƒ—å¾Œã«ã€è¡Œå‹•ã®çµæœã¨ãªã‚‹å ±é…¬\\(R_{t+1}\\)ã¨æ¬¡ã®çŠ¶æ…‹\\(S_{t+1}\\)ã‚’ç²å¾—ã™ã‚‹ã€‚\n\nãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ã§ã¯ã€æ¬¡ã«èµ·ã“ã‚‹äº‹è±¡ã®ç¢ºç‡ãŒã€ç¾åœ¨ã®çŠ¶æ…‹ã«ã‚ˆã£ã¦ã®ã¿æ±ºå®šã•ã‚Œã‚‹ã€‚ã¤ã¾ã‚Šã€å„çŠ¶æ…‹ã¯å°†æ¥çš„ãªå ±é…¬ã«ã©ã‚Œã»ã©å½±éŸ¿ã™ã‚‹ã®ã‹ã¨ã„ã£ãŸæƒ…å ±ã‚’æŒãŸãªã‘ã‚Œã°ã„ã‘ãªã„ã€‚ã“ã‚ŒãŒæº€ãŸã•ã‚Œã‚‹ã¨ãã€ãƒãƒ«ã‚³ãƒ•æ€§ã‚’æŒã¤ã¨ã„ã‚ã‚Œã‚‹ã€‚"
  },
  {
    "objectID": "chapter3.html#ç›®çš„ã¨å ±é…¬",
    "href": "chapter3.html#ç›®çš„ã¨å ±é…¬",
    "title": "ç¬¬ï¼“ç«  æœ‰é™ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹",
    "section": "ç›®çš„ã¨å ±é…¬",
    "text": "ç›®çš„ã¨å ±é…¬\nå ±é…¬ä¿¡å·ã¯æœ€çµ‚ç›®æ¨™"
  },
  {
    "objectID": "chapter3.html#åç›Šã¨ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰",
    "href": "chapter3.html#åç›Šã¨ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰",
    "title": "ç¬¬ï¼“ç«  æœ‰é™ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹",
    "section": "åç›Šã¨ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰",
    "text": "åç›Šã¨ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰"
  },
  {
    "objectID": "chapter3.html#ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çš„ã‚¿ã‚¹ã‚¯ã¨é€£ç¶šã‚¿ã‚¹ã‚¯ã®çµ±ä¸€çš„è¨˜æ³•",
    "href": "chapter3.html#ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çš„ã‚¿ã‚¹ã‚¯ã¨é€£ç¶šã‚¿ã‚¹ã‚¯ã®çµ±ä¸€çš„è¨˜æ³•",
    "title": "ç¬¬ï¼“ç«  æœ‰é™ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹",
    "section": "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çš„ã‚¿ã‚¹ã‚¯ã¨é€£ç¶šã‚¿ã‚¹ã‚¯ã®çµ±ä¸€çš„è¨˜æ³•",
    "text": "ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çš„ã‚¿ã‚¹ã‚¯ã¨é€£ç¶šã‚¿ã‚¹ã‚¯ã®çµ±ä¸€çš„è¨˜æ³•"
  },
  {
    "objectID": "chapter3.html#æ–¹ç­–ã¨ä¾¡å€¤é–¢æ•°",
    "href": "chapter3.html#æ–¹ç­–ã¨ä¾¡å€¤é–¢æ•°",
    "title": "ç¬¬ï¼“ç«  æœ‰é™ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹",
    "section": "æ–¹ç­–ã¨ä¾¡å€¤é–¢æ•°",
    "text": "æ–¹ç­–ã¨ä¾¡å€¤é–¢æ•°"
  }
]