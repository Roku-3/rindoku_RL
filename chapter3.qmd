---
jupyter: python3
---

# 第３章 有限マルコフ決定過程

バンディット問題での各行動$a$に価値$q_*(a)$を推定した。

有限マルコフ決定過程（有限MDP）では状態$s$における行動価値$q_*(s,a)$と、最適な行動選択のもとでの状態の価値$v_*(s)$を推定する。

## エージェントと環境の境界

各ステップ$t$ごとにエージェントは環境の状態$S$をもとに行動$A$を選択する。1ステップ後に、行動の結果となる報酬$R_{t+1}$と次の状態$S_{t+1}$を獲得する。

![](images/paste-74DCA7F3.png)

マルコフ決定過程では、次に起こる事象の確率が、**現在の状態によってのみ決定される**。つまり、各状態は将来的な報酬にどれほど影響するのかといった情報を持たなければいけない。これが満たされるとき、**マルコフ性**を持つといわれる。

## 目的と報酬

報酬信号は最終目標

## 収益とエピソード

## エピソード的タスクと連続タスクの統一的記法

![](images/paste-805051E4.png)

## 方策と価値関数

![](images/paste-C3F14B56.png)
