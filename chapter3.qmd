---
jupyter: python3
---

# 第３章 有限マルコフ決定過程

バンディット問題での各行動$a$に価値$q_*(a)$を推定した。

有限マルコフ決定過程（有限MDP）では状態$s$における行動価値$q_*(s,a)$と、最適な行動選択のもとでの状態の価値$v_*(s)$を推定する。

## エージェントと環境の境界

各ステップ$t$ごとにエージェントは環境の状態$S$をもとに行動$A$を選択する。1ステップ後に、行動の結果となる報酬$R_{t+1}$と次の状態$S_{t+1}$を獲得する。

![](images/paste-74DCA7F3.png)

MDPでは次のような**軌道(trajectory)**を生成する。

$$
S_0,A_0,R_1,S_1,A_1,R_2,S_2,A_2,R_3,...
$$

## 目的と報酬

報酬信号は最終目標

## 収益とエピソード

## エピソード的タスクと連続タスクの統一的記法

![](images/paste-805051E4.png)

## 方策と価値関数

![](images/paste-C3F14B56.png)
